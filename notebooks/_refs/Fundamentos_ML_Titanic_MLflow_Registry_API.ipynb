{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ee5610",
   "metadata": {},
   "source": [
    "\n",
    "# Titanic + **MLflow Model Registry** + API (v1/v2, Staging/Production)\n",
    "\n",
    "Este notebook cria um fluxo **completo** usando **MLflow Tracking + Model Registry**:\n",
    "\n",
    "1. **Setup do MLflow Server** (Tracking + Registry) ‚Äî usando **SQLite** como backend e artefatos locais.\n",
    "2. Treino de **v1** e **v2** (RandomForest com hiperpar√¢metros diferentes), logging de m√©tricas/artefatos.\n",
    "3. **Registro** das vers√µes no **Model Registry** como `titanic_rf`:\n",
    "   - `v1` ‚Üí **Production**\n",
    "   - `v2` ‚Üí **Staging**\n",
    "4. **Consumo por est√°gio**: carregar `models:/titanic_rf/Production` e `.../Staging` e comparar previs√µes.\n",
    "5. **API FastAPI** com sele√ß√£o por **stage** (Production/Staging) e testes com `TestClient`.\n",
    "6. **Promo√ß√£o de vers√£o** (ex.: mover v2 ‚Üí Production).\n",
    "\n",
    "> **Pr√©-requisitos** no seu ambiente:  \n",
    "> `pip install mlflow fastapi uvicorn scikit-learn pandas numpy pydantic`\n",
    "\n",
    "> **Importante**: Para o **Model Registry** funcionar, voc√™ precisa rodar o **mlflow server** em **outro terminal** (c√©lula abaixo mostra os comandos). O Registry **n√£o** funciona com `file:` tracking URI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509337a",
   "metadata": {},
   "source": [
    "## 0) Instru√ß√µes para iniciar o MLflow Server (em outro terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8113c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comando para rodar em OUTRO terminal ===\n",
      "\n",
      "mlflow server   --backend-store-uri \"sqlite:////home/vinicius/git/machine_learning/titanic/mlflow.db\"   --default-artifact-root \"/home/vinicius/git/machine_learning/titanic/mlartifacts\"   --host 0.0.0.0 --port 5000\n",
      "\n",
      "\n",
      "Acesse a UI em: http://localhost:5000\n",
      "Este notebook vai usar: MLFLOW_TRACKING_URI = http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, pathlib, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\".\").resolve()\n",
    "db_uri = f\"sqlite:///{(BASE / 'mlflow.db').as_posix()}\"\n",
    "art_root = (BASE / \"mlartifacts\").as_posix()\n",
    "print(\"=== Comando para rodar em OUTRO terminal ===\")\n",
    "print(textwrap.dedent(f\"\"\"\n",
    "mlflow server \\\n",
    "  --backend-store-uri \"{db_uri}\" \\\n",
    "  --default-artifact-root \"{art_root}\" \\\n",
    "  --host 0.0.0.0 --port 5000\n",
    "\"\"\"))\n",
    "print(\"\\nAcesse a UI em: http://localhost:5000\")\n",
    "print(\"Este notebook vai usar: MLFLOW_TRACKING_URI = http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc52e192",
   "metadata": {},
   "source": [
    "## 1) Imports e configura√ß√£o do Tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640d91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:29:06 INFO mlflow.tracking.fluent: Experiment with name 'titanic_registry_demo' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = Path(\".\"); DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "train_path = DATA_DIR / \"train.csv\"\n",
    "\n",
    "# IMPORTANT: server deve estar rodando em outro terminal\n",
    "TRACKING_URI = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(\"titanic_registry_demo\")\n",
    "\n",
    "client = MlflowClient(tracking_uri=TRACKING_URI)\n",
    "\n",
    "MODEL_NAME = \"titanic_rf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b766ac",
   "metadata": {},
   "source": [
    "## 2) Dados e pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f30be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar dados (coloque train.csv do Kaggle em ./data)\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "TARGET = \"Survived\"\n",
    "FEATURES_NUM = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "FEATURES_CAT = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "FEATURES_ALL = FEATURES_NUM + FEATURES_CAT\n",
    "\n",
    "X = train[FEATURES_ALL].copy()\n",
    "y = train[TARGET].values\n",
    "\n",
    "# Pr√©-processamento\n",
    "numeric = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler(with_mean=False))])\n",
    "categorical = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))])\n",
    "pre = ColumnTransformer([(\"num\", numeric, FEATURES_NUM), (\"cat\", categorical, FEATURES_CAT)])\n",
    "\n",
    "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "def auc_cv(pipe):\n",
    "    return cross_val_score(pipe, X, y, scoring=\"roc_auc\", cv=cv5, n_jobs=-1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9f843",
   "metadata": {},
   "source": [
    "## 3) Treinar e **logar v1** (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01cddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:29:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/27 14:29:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run v1_rf_baseline at: http://localhost:5000/#/experiments/1/runs/2056beafd7d34199b809f735ccd1c102\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "run_id_v1: 2056beafd7d34199b809f735ccd1c102 | AUC(v1): 0.872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs:/2056beafd7d34199b809f735ccd1c102/model'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf_v1 = RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1)\n",
    "pipe_v1 = Pipeline([(\"prep\", pre), (\"clf\", rf_v1)])\n",
    "\n",
    "auc_v1 = float(auc_cv(pipe_v1))\n",
    "\n",
    "with mlflow.start_run(run_name=\"v1_rf_baseline\") as run:\n",
    "    mlflow.log_params({\"model\": \"RandomForestClassifier\", \"n_estimators\": 300, \"seed\": SEED})\n",
    "    mlflow.log_metric(\"cv_auc\", auc_v1)\n",
    "    pipe_v1.fit(X, y)\n",
    "    mlflow.sklearn.log_model(pipe_v1, artifact_path=\"model\")\n",
    "    run_id_v1 = run.info.run_id\n",
    "\n",
    "print(\"run_id_v1:\", run_id_v1, \"| AUC(v1):\", round(auc_v1, 4))\n",
    "v1_uri = f\"runs:/{run_id_v1}/model\"\n",
    "v1_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6dd87",
   "metadata": {},
   "source": [
    "## 4) Treinar e **logar v2** (ajustado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4814d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:29:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/27 14:29:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run v2_rf_tuned at: http://localhost:5000/#/experiments/1/runs/eba5e4a2d7bb448eb02cdd4779d5432f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n",
      "run_id_v2: eba5e4a2d7bb448eb02cdd4779d5432f | AUC(v2): 0.8745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs:/eba5e4a2d7bb448eb02cdd4779d5432f/model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_v2 = RandomForestClassifier(n_estimators=600, max_depth=8, min_samples_split=5, random_state=SEED, n_jobs=-1)\n",
    "pipe_v2 = Pipeline([(\"prep\", pre), (\"clf\", rf_v2)])\n",
    "\n",
    "auc_v2 = float(auc_cv(pipe_v2))\n",
    "\n",
    "with mlflow.start_run(run_name=\"v2_rf_tuned\") as run:\n",
    "    mlflow.log_params({\"model\": \"RandomForestClassifier\", \"n_estimators\": 600, \"max_depth\": 8, \"min_samples_split\": 5, \"seed\": SEED})\n",
    "    mlflow.log_metric(\"cv_auc\", auc_v2)\n",
    "    pipe_v2.fit(X, y)\n",
    "    mlflow.sklearn.log_model(pipe_v2, artifact_path=\"model\")\n",
    "    run_id_v2 = run.info.run_id\n",
    "\n",
    "print(\"run_id_v2:\", run_id_v2, \"| AUC(v2):\", round(auc_v2, 4))\n",
    "v2_uri = f\"runs:/{run_id_v2}/model\"\n",
    "v2_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155725cf",
   "metadata": {},
   "source": [
    "## 5) Criar/assegurar registro e **registrar v1/v2** no Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfe0d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'titanic_rf' already exists. Creating a new version of this model...\n",
      "2025/10/27 14:29:13 WARNING mlflow.tracking._model_registry.fluent: Run with id 2056beafd7d34199b809f735ccd1c102 has no artifacts at artifact path 'model', registering model based on models:/m-cf2095cafb314da587f23044183381d0 instead\n",
      "2025/10/27 14:29:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: titanic_rf, version 1\n",
      "Created version '1' of model 'titanic_rf'.\n",
      "Registered model 'titanic_rf' already exists. Creating a new version of this model...\n",
      "2025/10/27 14:29:13 WARNING mlflow.tracking._model_registry.fluent: Run with id eba5e4a2d7bb448eb02cdd4779d5432f has no artifacts at artifact path 'model', registering model based on models:/m-474e85f1740243758c8db2f69d6d93bc instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created registered model: titanic_rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/27 14:29:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: titanic_rf, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelVersion v1: 1 | source: models:/m-cf2095cafb314da587f23044183381d0\n",
      "ModelVersion v2: 2 | source: models:/m-474e85f1740243758c8db2f69d6d93bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'titanic_rf'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Garantir que o Registered Model existe\n",
    "try:\n",
    "    client.get_registered_model(MODEL_NAME)\n",
    "    print(\"Registered model exists:\", MODEL_NAME)\n",
    "except Exception:\n",
    "    client.create_registered_model(MODEL_NAME)\n",
    "    print(\"Created registered model:\", MODEL_NAME)\n",
    "\n",
    "# Registrar cada run como uma vers√£o do modelo\n",
    "mv1 = mlflow.register_model(model_uri=v1_uri, name=MODEL_NAME)\n",
    "mv2 = mlflow.register_model(model_uri=v2_uri, name=MODEL_NAME)\n",
    "print(\"ModelVersion v1:\", mv1.version, \"| source:\", mv1.source)\n",
    "print(\"ModelVersion v2:\", mv2.version, \"| source:\", mv2.source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a6488",
   "metadata": {},
   "source": [
    "## 6) **Definir est√°gios** (v1‚ÜíProduction, v2‚ÜíStaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b35093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 'Staging', 'eba5e4a2d7bb448eb02cdd4779d5432f'),\n",
       " ('1', 'Production', '2056beafd7d34199b809f735ccd1c102')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Transicionar est√°gios (note: precisa de permiss√£o no server; no local default √© permitido)\n",
    "client.transition_model_version_stage(name=MODEL_NAME, version=mv1.version, stage=\"Production\", archive_existing_versions=False)\n",
    "client.transition_model_version_stage(name=MODEL_NAME, version=mv2.version, stage=\"Staging\", archive_existing_versions=False)\n",
    "\n",
    "# Listar para confirmar\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "[(v.version, v.current_stage, v.run_id) for v in versions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a445dca",
   "metadata": {},
   "source": [
    "## 7) **Carregar por est√°gio** e comparar previs√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03c867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proba_production': [0, 1], 'proba_staging': [0, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import mlflow.pyfunc\n",
    "\n",
    "sample = pd.DataFrame([\n",
    "    {\"Age\": 22, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 7.25, \"Pclass\": 3, \"Sex\": \"male\", \"Embarked\": \"S\"},\n",
    "    {\"Age\": 38, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 71.2833, \"Pclass\": 1, \"Sex\": \"female\", \"Embarked\": \"C\"},\n",
    "])\n",
    "\n",
    "m_prod = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/Production\")\n",
    "m_stag = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/Staging\")\n",
    "\n",
    "# Ambos modelos foram logados como sklearn pipeline -> predict_proba dispon√≠vel via predict se wrapper exp√µe; para seguran√ßa:\n",
    "try:\n",
    "    p_prod = m_prod.predict(sample)  # pode retornar proba ou classe dependendo do flavor; sklearn geralmente tem predict\n",
    "except Exception:\n",
    "    # fallback: carregar como sklearn diretamente\n",
    "    m_prod = mlflow.sklearn.load_model(model_uri=f\"models:/{MODEL_NAME}/Production\")\n",
    "    p_prod = m_prod.predict_proba(sample)[:,1]\n",
    "\n",
    "try:\n",
    "    p_stg = m_stag.predict(sample)\n",
    "except Exception:\n",
    "    m_stag = mlflow.sklearn.load_model(model_uri=f\"models:/{MODEL_NAME}/Staging\")\n",
    "    p_stg = m_stag.predict_proba(sample)[:,1]\n",
    "\n",
    "{\"proba_production\": p_prod.tolist(), \"proba_staging\": p_stg.tolist()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60646a0",
   "metadata": {},
   "source": [
    "## 8) API (FastAPI) consultando por **stage** (Production/Staging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc60f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'production': {'stage': 'Production',\n",
       "  'probabilities': [0.08611111111111112, 1.0]},\n",
       " 'staging': {'stage': 'Staging',\n",
       "  'probabilities': [0.11172925081682045, 0.9972483013208947]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "class Passenger(BaseModel):\n",
    "    Age: Optional[float] = None\n",
    "    SibSp: Optional[int] = None\n",
    "    Parch: Optional[int] = None\n",
    "    Fare: Optional[float] = None\n",
    "    Pclass: Optional[int] = None\n",
    "    Sex: Optional[str] = None\n",
    "    Embarked: Optional[str] = None\n",
    "\n",
    "class PredictRequest(BaseModel):\n",
    "    stage: str  # \"Production\" ou \"Staging\"\n",
    "    inputs: List[Passenger]\n",
    "\n",
    "class PredictResponse(BaseModel):\n",
    "    stage: str\n",
    "    probabilities: List[float]\n",
    "\n",
    "app = FastAPI(title=\"Titanic Registry API\", version=\"1.0.0\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    # verifica se consegue listar vers√µes\n",
    "    try:\n",
    "        vers = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "        ok = True\n",
    "        details = [(v.version, v.current_stage) for v in vers]\n",
    "    except Exception as e:\n",
    "        ok = False\n",
    "        details = str(e)\n",
    "    return {\"ok\": ok, \"model\": MODEL_NAME, \"versions\": details}\n",
    "\n",
    "def _load_by_stage(stage: str):\n",
    "    # Primeiro tenta carregar como sklearn (para garantir predict_proba)\n",
    "    try:\n",
    "        model = mlflow.sklearn.load_model(model_uri=f\"models:/{MODEL_NAME}/{stage}\")\n",
    "        return (\"sklearn\", model)\n",
    "    except Exception:\n",
    "        # fallback: pyfunc e usar predict\n",
    "        model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{stage}\")\n",
    "        return (\"pyfunc\", model)\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictResponse)\n",
    "def predict(req: PredictRequest):\n",
    "    if req.stage not in {\"Production\", \"Staging\"}:\n",
    "        raise ValueError(\"stage must be 'Production' or 'Staging'\")\n",
    "    kind, model = _load_by_stage(req.stage)\n",
    "    df = pd.DataFrame([x.model_dump() for x in req.inputs])\n",
    "    if kind == \"sklearn\" and hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba(df)[:,1].tolist()\n",
    "    else:\n",
    "        out = model.predict(df)\n",
    "        # Se vier classes, adapte; aqui tentamos converter para list of floats\n",
    "        proba = [float(x) if not isinstance(x, (list, tuple, np.ndarray)) else float(x[0]) for x in np.atleast_1d(out)]\n",
    "    return PredictResponse(stage=req.stage, probabilities=proba)\n",
    "\n",
    "client_api = TestClient(app)\n",
    "\n",
    "# Testes locais\n",
    "payload = {\n",
    "    \"stage\":\"Production\",\n",
    "    \"inputs\":[\n",
    "        {\"Age\":22,\"SibSp\":1,\"Parch\":0,\"Fare\":7.25,\"Pclass\":3,\"Sex\":\"male\",\"Embarked\":\"S\"},\n",
    "        {\"Age\":38,\"SibSp\":1,\"Parch\":0,\"Fare\":71.2833,\"Pclass\":1,\"Sex\":\"female\",\"Embarked\":\"C\"}\n",
    "    ]\n",
    "}\n",
    "r_prod = client_api.post(\"/predict\", json=payload).json()\n",
    "r_stg  = client_api.post(\"/predict\", json={**payload, \"stage\":\"Staging\"}).json()\n",
    "{\"production\": r_prod, \"staging\": r_stg}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18136dc",
   "metadata": {},
   "source": [
    "## 9) Promo√ß√£o de vers√£o (ex.: v2 ‚Üí Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e888602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 'Staging'), ('1', 'Production')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Exemplo: promover v2 para Production (e mover v1 para Archived)\n",
    "# client.transition_model_version_stage(name=MODEL_NAME, version=mv2.version, stage=\"Production\", archive_existing_versions=True)\n",
    "\n",
    "# Mostra vers√µes e est√°gios atuais\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "[(v.version, v.current_stage) for v in versions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b9c95",
   "metadata": {},
   "source": [
    "## 10) Como rodar a API fora do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18301e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Em um terminal, com o MLflow Server rodando (porta 5000):\n",
      "\n",
      "uvicorn <este_notebook_ou_app>:app --host 0.0.0.0 --port 8000\n",
      "\n",
      "# Requisi√ß√£o:\n",
      "curl -X POST http://localhost:8000/predict -H \"Content-Type: application/json\" -d '{\n",
      "  \"stage\": \"Production\",\n",
      "  \"inputs\": [\n",
      "    {\"Age\": 22, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 7.25, \"Pclass\": 3, \"Sex\": \"male\", \"Embarked\": \"S\"}\n",
      "  ]\n",
      "}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\"\"\n",
    "# Em um terminal, com o MLflow Server rodando (porta 5000):\n",
    "\n",
    "uvicorn <este_notebook_ou_app>:app --host 0.0.0.0 --port 8000\n",
    "\n",
    "# Requisi√ß√£o:\n",
    "curl -X POST http://localhost:8000/predict -H \"Content-Type: application/json\" -d '{\n",
    "  \"stage\": \"Production\",\n",
    "  \"inputs\": [\n",
    "    {\"Age\": 22, \"SibSp\": 1, \"Parch\": 0, \"Fare\": 7.25, \"Pclass\": 3, \"Sex\": \"male\", \"Embarked\": \"S\"}\n",
    "  ]\n",
    "}'\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
