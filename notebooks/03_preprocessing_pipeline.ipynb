{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150608e0",
   "metadata": {},
   "source": [
    "# 03 - r√©-Processamento e Constru√ß√£o do Pipeline (scikit-learn)\n",
    "\n",
    "<a href=\"../README.md\" title=\"Voltar para a p√°gina principal\">\n",
    "üè† Voltar para Home\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a92de7f",
   "metadata": {},
   "source": [
    "## Vis√£o Geral\n",
    "\n",
    "Este notebook implementa o *pr√©-processamento completo* do dataset para modelos de Machine Learning, seguindo boas pr√°ticas recomendadas pela biblioteca scikit-learn.\n",
    "\n",
    "## O pipeline final incluir√°:\n",
    "\n",
    "1. Separa√ß√£o entre features num√©ricas e categ√≥ricas\n",
    "2. Imputa√ß√£o de valores ausentes\n",
    "3. Codifica√ß√£o de vari√°veis categ√≥ricas (One-Hot Encoding)\n",
    "4. Padroniza√ß√£o de vari√°veis num√©ricas\n",
    "5. Montagem do ColumnTransformer\n",
    "6. Gera√ß√£o do conjunto final X_prepared e y\n",
    "\n",
    "Este notebook prepara os dados para os pr√≥ximos passos:\n",
    "\n",
    "- 04_modelos_classicos.ipynb\n",
    "- 05_modelos_avancados.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6386f93",
   "metadata": {},
   "source": [
    "# Importa√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e71946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Trabalho com html\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265228c2",
   "metadata": {},
   "source": [
    "# 1. Carregamento e Visualiza√ß√£o Preliminar\n",
    "\n",
    "***Descri√ß√£o:*** Utilizando o dataset de acompanhamento operacional dos pedidos tratados.\n",
    "> **Arquivo e:** database/processed/acompanhamento_operacional_FE.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd588b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado com sucesso!\n",
      "Formato: (488398, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigla_cliente</th>\n",
       "      <th>tipo_veiculo</th>\n",
       "      <th>qtde_itens</th>\n",
       "      <th>volume</th>\n",
       "      <th>peso</th>\n",
       "      <th>m3</th>\n",
       "      <th>uf</th>\n",
       "      <th>fl_base</th>\n",
       "      <th>representante</th>\n",
       "      <th>flag_entrega_agendada</th>\n",
       "      <th>...</th>\n",
       "      <th>horas_conferencia</th>\n",
       "      <th>horas_emissao</th>\n",
       "      <th>horas_analise_producao</th>\n",
       "      <th>horas_minuta</th>\n",
       "      <th>horas_exped_minuta</th>\n",
       "      <th>hora_analise_transporte</th>\n",
       "      <th>lead_time_total_horas</th>\n",
       "      <th>complexidade_operacional</th>\n",
       "      <th>pedido_grande_flag</th>\n",
       "      <th>processo_longo_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTL</td>\n",
       "      <td>TRUCK 70 M3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>MS</td>\n",
       "      <td>0</td>\n",
       "      <td>N√ÉO DEFINIDO</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NTL</td>\n",
       "      <td>TRUCK 70 M3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130.30</td>\n",
       "      <td>2.33</td>\n",
       "      <td>MS</td>\n",
       "      <td>0</td>\n",
       "      <td>N√ÉO DEFINIDO</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NTL</td>\n",
       "      <td>TRUCK 70 M3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.00</td>\n",
       "      <td>2.22</td>\n",
       "      <td>SC</td>\n",
       "      <td>0</td>\n",
       "      <td>SC CARGO TRANSPORTES LTDA</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>TRUCK 75 M3</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>182.79</td>\n",
       "      <td>1.08</td>\n",
       "      <td>CE</td>\n",
       "      <td>0</td>\n",
       "      <td>VELOMAX BRASIL TRANSPORTES LTD</td>\n",
       "      <td>N√£o</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>TRUCK 70 M3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>25.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>CE</td>\n",
       "      <td>0</td>\n",
       "      <td>MFM TRANSPORTES</td>\n",
       "      <td>Sim</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sigla_cliente tipo_veiculo  qtde_itens  volume    peso    m3  uf  fl_base  \\\n",
       "0           NTL  TRUCK 70 M3           1       1  144.30  2.10  MS        0   \n",
       "1           NTL  TRUCK 70 M3           1       1  130.30  2.33  MS        0   \n",
       "2           NTL  TRUCK 70 M3           1       1   97.00  2.22  SC        0   \n",
       "3           MMM  TRUCK 75 M3           7      43  182.79  1.08  CE        0   \n",
       "4           MMM  TRUCK 70 M3           4       9   25.50  0.07  CE        0   \n",
       "\n",
       "                    representante flag_entrega_agendada  ...  \\\n",
       "0                    N√ÉO DEFINIDO                   N√£o  ...   \n",
       "1                    N√ÉO DEFINIDO                   N√£o  ...   \n",
       "2       SC CARGO TRANSPORTES LTDA                   N√£o  ...   \n",
       "3  VELOMAX BRASIL TRANSPORTES LTD                   N√£o  ...   \n",
       "4                 MFM TRANSPORTES                   Sim  ...   \n",
       "\n",
       "  horas_conferencia  horas_emissao  horas_analise_producao  horas_minuta  \\\n",
       "0               0.0            0.0                    22.0           0.0   \n",
       "1               0.0            0.0                    22.0           0.0   \n",
       "2               0.0            0.0                     0.0           0.0   \n",
       "3               1.0            0.0                    11.0          99.0   \n",
       "4               1.0            0.0                    12.0         172.0   \n",
       "\n",
       "   horas_exped_minuta  hora_analise_transporte  lead_time_total_horas  \\\n",
       "0                16.0                    161.0                  229.0   \n",
       "1                16.0                    165.0                  234.0   \n",
       "2                16.0                     40.0                  249.0   \n",
       "3                 8.0                     93.0                  266.0   \n",
       "4                16.0                    285.0                  542.0   \n",
       "\n",
       "   complexidade_operacional  pedido_grande_flag  processo_longo_flag  \n",
       "0                         1                   0                    0  \n",
       "1                         1                   0                    0  \n",
       "2                         1                   0                    0  \n",
       "3                         7                   1                    0  \n",
       "4                         4                   1                    1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../database/processed/acompanhamento_operacional_FE.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset carregado com sucesso!\")\n",
    "print(\"Formato:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811d249",
   "metadata": {},
   "source": [
    "# 2. Identificar Vari√°veis Num√©rcias e Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e97b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display: flex; gap: 50px; justify-content: left;\">\n",
       "\n",
       "    <div>\n",
       "        <h3 style=\"text-align:center;\">Summary</h3>\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tipo</th>\n",
       "      <th>qtde</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numerico</td>\n",
       "      <td>22</td>\n",
       "      <td>[qtde_itens, volume, peso, m3, fl_base, qtde_ocams, peso_cubado_rodoviario, horas_pre_conferencia, horas_distribuicao_cotas, horas_planejamento, horas_divisao_ocam, horas_coleta, horas_conferencia, horas_emissao, horas_analise_producao, horas_minuta, horas_exped_minuta, hora_analise_transporte, lead_time_total_horas, complexidade_operacional, pedido_grande_flag, processo_longo_flag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>categorico</td>\n",
       "      <td>6</td>\n",
       "      <td>[sigla_cliente, tipo_veiculo, uf, representante, flag_entrega_agendada, modalidade]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TARGET = \"fl_atraso_cli\"\n",
    "\n",
    "# Remover target para an√°lise inicial\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "num_cols = [c for c in num_cols if c != TARGET]\n",
    "\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Cria o DataFrame-resumo\n",
    "df_summary = pd.DataFrame({\n",
    "    'tipo': ['numerico', 'categorico'],\n",
    "    'qtde': [len(num_cols), len(cat_cols)],\n",
    "    'features': [num_cols, cat_cols]\n",
    "})\n",
    "\n",
    "html = f\"\"\"\n",
    "<div style=\"display: flex; gap: 50px; justify-content: left;\">\n",
    "\n",
    "    <div>\n",
    "        <h3 style=\"text-align:center;\">Summary</h3>\n",
    "        {df_summary.to_html(index=True)}\n",
    "    </div>\n",
    "\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e35b41",
   "metadata": {},
   "source": [
    "# 3. Estrat√©gia de Imputa√ß√£o (num√©ricas e categ√≥ricas)\n",
    "\n",
    "**Descri√ß√£o:** a estrat√©gia de imputa√ß√£o refere-se aos m√©todos usados para preencher valores ausentes (dados faltantes) em um conjunto de dados. A escolha do m√©todo depende do tipo de dados (num√©ricos ou categ√≥ricos), do volume de dados faltantes e do padr√£o de aus√™ncia, visando minimizar o vi√©s e maximizar a precis√£o do modelo final.\n",
    "\n",
    "**Estrat√©gias recomendadas:**\n",
    "- **Num√©ricas:** Usar median por ser robusto contra outliers e a mediana n√£o √© afetada por caudas pesadas.\n",
    "- **Categ√≥ricas:** Usar most_frequent (moda), pois evita criar categoria artificial, mant√©m coer√™ncia sendo o padr√£o mais recomendado para categorias como UF, modalidade, sigla do cliente etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72281342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputadores definidos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Imputa√ß√£o num√©rica: mediana -> robusta a outliers\n",
    "numeric_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Imputa√ß√£o categ√≥rica: moda -> mant√©m consist√™ncia\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "print(\"Imputadores definidos com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bfb5b",
   "metadata": {},
   "source": [
    "# 4. Codifica√ß√£o Categ√≥rica (OneHot Encoding)\n",
    "\n",
    "**Descri√ß√£o:** A etapa de codifica√ß√£o categ√≥rica transforma vari√°veis textuais em representa√ß√µes num√©ricas adequadas para modelos de Machine Learning.  \n",
    "Modelos matem√°ticos n√£o conseguem interpretar textos como ‚ÄúSP‚Äù, ‚ÄúRodovi√°rio‚Äù, ‚ÄúHR‚Äù ou ‚ÄúCliente X‚Äù. Por isso, utilizamos o OneHotEncoder, que converte cada categoria em uma coluna bin√°ria (0 ou 1).\n",
    "\n",
    "**Usando OneHotEncoder:** \n",
    "√â o m√©todo mais seguro e universal para modelos cl√°ssicos, como Regress√£o Log√≠stica, √Årvores, Random Forest e Gradient Boosting.  \n",
    "- **O par√¢metro handle_unknown=\"ignore\"** evita falhas durante o deploy caso surja uma categoria nova.  \n",
    "- **O par√¢metro sparse_output=False** permite visualizar o dataframe transformado em formato denso, facilitando debug, salvamento e inspe√ß√£o.  \n",
    "\n",
    "**Benef√≠cios:**\n",
    "\n",
    "- Elimina a escala arbitr√°ria de categorias.\n",
    "- Evita ordinalidade falsa (ex.: SP > RJ?).\n",
    "- Permite ao modelo capturar rela√ß√µes espec√≠ficas entre categorias e o atraso.\n",
    "- Torna o pipeline mais robusto para uso em produ√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa3f68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder configurado!\n"
     ]
    }
   ],
   "source": [
    "# 4. Encoding Categ√≥rico (OneHot)\n",
    "categorical_encoder = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "print(\"OneHotEncoder configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db285868",
   "metadata": {},
   "source": [
    "# 5. Scaling (Padroniza√ß√£o das Vari√°veis Num√©ricas)\n",
    "\n",
    "**Descri√ß√£o:** A padroniza√ß√£o √© uma etapa fundamental na prepara√ß√£o dos dados, especialmente para modelos sens√≠veis √† escala das vari√°veis. Neste projeto, utilizamos o StandardScaler, que transforma todas as vari√°veis num√©ricas para uma escala comum, com m√©dia 0 e desvio padr√£o 1.\n",
    "\n",
    "**Motiva√ß√µes para o uso do StandardScaler:**\n",
    "- Vari√°veis como volume, peso e horas operacionais possuem escalas muito diferentes.\n",
    "- Modelos como Regress√£o Log√≠stica, SVM, KNN e Redes Neurais exigem escalas compar√°veis para funcionar adequadamente.\n",
    "- A padroniza√ß√£o evita que o modelo interprete erroneamente vari√°veis com escala maior como sendo mais importantes.\n",
    "\n",
    "**Vantagens:**\n",
    "- Aumenta a estabilidade num√©rica do modelo.\n",
    "- Melhora a converg√™ncia de algoritmos baseados em gradiente.\n",
    "- Reduz o vi√©s provocado por features com magnitude exagerada.\n",
    "\n",
    "Assim como no imputer e no encoder, aqui configuramos o StandardScaler, mas sua aplica√ß√£o real acontece somente dentro do Pipeline, durante o .fit(), garantindo transforma√ß√£o consistente tanto no treino quanto na infer√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225a16be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler definido!\n"
     ]
    }
   ],
   "source": [
    "# 5. Scaling num√©rico\n",
    "numeric_scaler = StandardScaler()\n",
    "\n",
    "print(\"Scaler definido!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cefbd7",
   "metadata": {},
   "source": [
    "# 6. ColumnTransformer ‚Äî Unindo o Processo\n",
    "\n",
    "**Descri√ß√£o:** Ap√≥s definir os componentes individuais (imputers, encoder e scaler), esta etapa consolida todos esses elementos dentro de um √∫nico bloco de pr√©-processamento usando o ColumnTransformer.\n",
    "\n",
    "Cada grupo de vari√°veis (num√©ricas e categ√≥ricas) recebe seu pr√≥prio pipeline especializado:\n",
    "\n",
    "**Pipeline Num√©rico:**\n",
    "- Imputa√ß√£o por mediana\n",
    "- Padroniza√ß√£o com StandardScaler\n",
    "\n",
    "**Ppeline Categ√≥rico:**\n",
    "- Iputa√ß√£o por moda\n",
    "- Codifica√ß√£o com OneHotEncoder\n",
    "\n",
    "O ColumnTransformer garante que cada transforma√ß√£o seja aplicada apenas ao tipo correto de vari√°vel, preservando integridade, modularidade e reprodutibilidade do pipeline.  \n",
    "A aplica√ß√£o pr√°tica das transforma√ß√µes ocorrer√° somente no momento do fit() do modelo, onde o pipeline executa imputa√ß√£o, codifica√ß√£o e escala em um s√≥ fluxo, produzindo dados consistentes tanto no treino quanto na infer√™ncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84ac67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 6. Constru√ß√£o do ColumnTransformer\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", Pipeline(steps=[\n",
    "        (\"imputer\", numeric_imputer),\n",
    "        (\"scaler\", numeric_scaler)\n",
    "    ]), num_cols),\n",
    "\n",
    "    (\"cat_pipeline\", Pipeline(steps=[\n",
    "        (\"imputer\", categorical_imputer),\n",
    "        (\"encoder\", categorical_encoder)\n",
    "    ]), cat_cols)\n",
    "])\n",
    "\n",
    "print(\"ColumnTransformer criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ed688",
   "metadata": {},
   "source": [
    "# 7. Split Train/Test\n",
    "\n",
    "**Descri√ß√£o:** Nesta etapa, dividimos o dataset em dois subconjuntos principais:\n",
    "\n",
    "**Treino (70%):** Usado para ajustar o pipeline de pr√©-processamento e treinar os modelos.\n",
    "\n",
    "**Teste (20%):** Usado apenas ap√≥s a modelagem, para medir o desempenho real do modelo em dados nunca vistos.\n",
    "\n",
    "Utilizamos stratify=y para manter a propor√ß√£o original de atrasos/n√£o atrasos, garantindo que o conjunto de treino e teste representem adequadamente o problema.\n",
    "\n",
    "Essa separa√ß√£o impede vazamento de informa√ß√£o e garante avalia√ß√£o honesta da performance dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29c776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split realizado!\n",
      "Treino: (341878, 28)\n",
      "Teste: (146520, 28)\n"
     ]
    }
   ],
   "source": [
    "# 7. Train/Test Split\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Split realizado!\")\n",
    "print(\"Treino:\", X_train.shape)\n",
    "print(\"Teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de63e121",
   "metadata": {},
   "source": [
    "# 8. Pipeline Final (Pr√©-processamento completo)\n",
    "\n",
    "**Descri√ß√£o:** Nesta etapa constru√≠mos o pipeline completo de modelagem, combinando:\n",
    "\n",
    "- imputa√ß√£o de valores ausentes\n",
    "- codifica√ß√£o categ√≥rica (OneHotEncoder)\n",
    "- padroniza√ß√£o de vari√°veis num√©ricas\n",
    "- integra√ß√£o via ColumnTransformer\n",
    "\n",
    "O uso de um Pipeline garante reprodutibilidade, preven√ß√£o de vazamento de informa√ß√£o e padroniza√ß√£o do fluxo de transforma√ß√£o.\n",
    "Agora, quando executarmos .fit(), todo o pr√©-processamento ser√° aplicado automaticamente antes do treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09220ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline de pr√©-processamento pronto!\n"
     ]
    }
   ],
   "source": [
    "# 8. Pipeline Final de Pr√©-processamento\n",
    "pipeline_preprocess = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess)\n",
    "])\n",
    "\n",
    "print(\"Pipeline de pr√©-processamento pronto!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
